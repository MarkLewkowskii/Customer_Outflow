# -*- coding: utf-8 -*-
"""04_evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/MarkLewkowskii/Customer_Outflow/blob/main/notebooks/04_evaluation.ipynb

# Оцінка моделей
"""

import pandas as pd
import os
from sklearn.metrics import classification_report
from joblib import load

"""Зчитування файлу processed_data.csv."""

df = pd.read_csv("data/processed/processed_data.csv")

X = df[df.columns[1:-1]]
y = df[df.columns[-1:]].values.flatten()

"""__Функція для виведення класифікаційного звіту__"""

def model_classification_report(model, model_name: str, X_test, y_test):
    y_pred = model.predict(X_test)
    print(
        f"Класифікаційний звіт для моделі {model_name}:\n",
        classification_report(y_test, y_pred),
    )

"""__Функція для виведення розміру моделі__"""

def model_size(model_path: str):
    size_in_bytes = os.path.getsize(model_path)
    size_in_kb = size_in_bytes / 1024
    size_in_mb = size_in_kb / 1024
    print(
        f"Розмір моделі: {size_in_bytes} B ({size_in_kb:.2f} kB / {size_in_mb:.2f} MB)"
    )
    return size_in_bytes

"""Завантаження моделей."""

model_RF_path = "models/model_RandomForest.joblib"
model_HGB_path = "models/model_HistGradientBoosting.joblib"
model_GB_path = "models/model_GradientBoosting.joblib"
model_LR_path = "models/model_LogisticRegression.joblib"

model_RF = load(model_RF_path)
model_HGB = load(model_HGB_path)
model_GB = load(model_GB_path)
model_LR = load(model_LR_path)

model_RF_name = "Random Forest"
model_HGB_name = "Histogram-based Gradient Boosting Classification Tree"
model_GB_name = "Gradient Boosting"
model_LR_name = "Logistic Regression"

"""__Модель Random Forest__"""

model_classification_report(model_RF, model_RF_name, X, y)
model_RF_size = model_size(model_RF_path)

"""__Модель Histogram-based Gradient Boosting Classification Tree__"""

model_classification_report(model_HGB, model_HGB_name, X, y)
model_HGB_size = model_size(model_HGB_path)

"""__Модель Gradient Boosting__"""

model_classification_report(model_GB, model_GB_name, X, y)
model_GB_size = model_size(model_GB_path)

"""__Модель Logistic Regression__"""

model_classification_report(model_LR, model_LR_name, X, y)
model_LR_size = model_size(model_LR_path)

"""__Відсоткове співвідношення розмірів моделей__"""

sum_sizes = model_RF_size + model_HGB_size + model_GB_size + model_LR_size
print(f"{model_RF_name}: {model_RF_size / sum_sizes * 100:.2f}%")
print(f"{model_HGB_name}: {model_HGB_size / sum_sizes * 100:.2f}%")
print(f"{model_GB_name}: {model_GB_size / sum_sizes * 100:.2f}%")
print(f"{model_LR_name}: {model_LR_size / sum_sizes * 100:.2f}%")

import json


# Шлях до файлу для збереження даних
results_path = "results/model_evaluation.json"

# Функція для збереження даних у JSON-файл
def save_results_to_json(model_name, classification_report, model_size):
    # Перевіряємо, чи файл вже існує
    if os.path.exists(results_path):
        with open(results_path, "r") as f:
            results = json.load(f)
    else:
        results = {}

    # Додаємо дані для поточної моделі
    results[model_name] = {
        "classification_report": classification_report,
        "model_size_mb": model_size,
    }

    # Записуємо результати у JSON-файл
    with open(results_path, "w") as f:
        json.dump(results, f, indent=4)

# Приклад для Random Forest
model_RF_report = classification_report(y, model_RF.predict(X), output_dict=True)
model_RF_size_mb = model_size(model_RF_path) / (1024 * 1024)  # Конвертуємо в MB
save_results_to_json(model_RF_name, model_RF_report, model_RF_size_mb)

# Повторюємо для інших моделей
model_HGB_report = classification_report(y, model_HGB.predict(X), output_dict=True)
model_HGB_size_mb = model_size(model_HGB_path) / (1024 * 1024)
save_results_to_json(model_HGB_name, model_HGB_report, model_HGB_size_mb)

model_GB_report = classification_report(y, model_GB.predict(X), output_dict=True)
model_GB_size_mb = model_size(model_GB_path) / (1024 * 1024)
save_results_to_json(model_GB_name, model_GB_report, model_GB_size_mb)

model_LR_report = classification_report(y, model_LR.predict(X), output_dict=True)
model_LR_size_mb = model_size(model_LR_path) / (1024 * 1024)
save_results_to_json(model_LR_name, model_LR_report, model_LR_size_mb)

"""## Висновки

Розглянуто чотири моделі з бібліотеки `sklearn`. Здійснено оцінку *точності* моделей на усіх даних і на тестових даних за допомогою `classification_report` та *розміру* моделей.

**Рейтинг моделей за точність на тестових даних (починаючи від найточнішої):**

1. *Random Forest* та *Histogram-based Gradient Boosting Classification Tree*: 97%
2. *Gradient Boosting*: 96%
3. *Logistic Regression*: 89%

**Коментарі:** Моделі *Random Forest* та *Histogram-based Gradient Boosting Classification Tree* показали однакові значення метрик якості. Метод *Gradient Boosting* має трохи нижчі значення метрик якості. Модель *Logistic Regression* має відчутно меншу точність ніж усі інші, але однаково залишається досить точною.

**Рейтинг моделей за точність на усіх даних (починаючи від найточнішої):**

1. *Random Forest*: 99%
2. *Histogram-based Gradient Boosting Classification Tree*: 98%
3. *Gradient Boosting*: 97%
4. *Logistic Regression*: 89%

**Коментарі:** На усіх даних найточнішою є модель *Random Forest*. Точність моделі *Histogram-based Gradient Boosting Classification Tree* менше ніж *Random Forest*, але різниця невелика. У моделі *Gradient Boosting* нижче точність ніж у *Histogram-based Gradient Boosting Classification Tree*, але різниця також невелика. Модель *Logistic Regression* має відчутно меншу точність ніж усі інші, але однаково залишається досить точною.

**Рейтинг моделей за розміром (починаючи від найменшої):**

1. *Logistic Regression*: 1.41 kB (0.00% від суми розмірів усіх моделей)
2. *Gradient Boosting*: 0.88 MB (2.4% від суми розмірів усіх моделей)
3. *Histogram-based Gradient Boosting Classification Tree*: 1.88 MB (5.12% від суми розмірів усіх моделей)
4. *Random Forest*: 34.03 MB (92.47% від суми розмірів усіх моделей)

**Коментарі:** Модель *Random Forest* важить набагато більше ніж інші моделі. Модель *Gradient Boosting* важить менше ніж *Histogram-based Gradient Boosting Classification Tree*, але різниця не є суттєвою. Модель *Logistic Regression* займає мінімальну кількість пам'яті.

**Підсумуємо результати:**

- Найточнішою є модель *Random Forest*, але й важить вона набагато більше ніж інші моделі.
- Точність моделі *Histogram-based Gradient Boosting Classification Tree* трохи менше ніж у моделі *Random Forest*, але важить вона набагато менше. Також саме ця модель найкраще себе показала на тестових даних.
- Модель *Gradient Boosting* має трохи нижчу точність та розмір ніж модель *Histogram-based Gradient Boosting Classification Tree*, але різниця не є суттєвою.
- Модель *Logistic Regression* має відчутно меншу точність ніж усі інші, але однаково залишається досить точною. До того ж модель займає мінімальну кількість пам'яті. Для *задачі прогнозування відтоку клієнтів* висока точність не є критично необхідною, тому модель має право на існування.

**Рекомендації:**

- Якщо обирати "золоту середину" між точністю та розміром, то варто обрати *Histogram-based Gradient Boosting Classification Tree*. Модель має високу точність і невеликий розмір.
- Якщо критично важлива точність, то варто обрати *Random Forest*.
- Якщо критично важливим є розмір, то варто обрати *Logistic Regression*.
"""