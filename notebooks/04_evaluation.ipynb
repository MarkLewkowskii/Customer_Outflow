{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оцінка моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зчитування файлу processed_data.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[1:-1]]\n",
    "y = df[df.columns[-1:]].values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Функція для виведення класифікаційного звіту__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_classification_report(model, model_name: str, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\n",
    "        f\"Класифікаційний звіт для моделі {model_name}:\\n\",\n",
    "        classification_report(y_test, y_pred),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Функція для виведення розміру моделі__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_size(model_path: str):\n",
    "    size_in_bytes = os.path.getsize(model_path)\n",
    "    size_in_kb = size_in_bytes / 1024\n",
    "    size_in_mb = size_in_kb / 1024\n",
    "    print(\n",
    "        f\"Розмір моделі: {size_in_bytes} B ({size_in_kb:.2f} kB / {size_in_mb:.2f} MB)\"\n",
    "    )\n",
    "    return size_in_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Функції для визначення важливості ознак моделі__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для *Random Forest* і *Gradient Boosting*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_weights(model) -> dict:\n",
    "    \"\"\"\n",
    "    Функція повертає ваги усіх ознак.\n",
    "    \"\"\"\n",
    "    weights_dict =  {\n",
    "        name: weight\n",
    "        for name, weight in zip(\n",
    "            model.feature_names_in_, model.feature_importances_\n",
    "        )\n",
    "    }\n",
    "    return dict(sorted(weights_dict.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_importances(weights: dict):\n",
    "    \"\"\"\n",
    "    Функція повертає важливі і неважливі ознаки в залежності від заданої точності.\n",
    "    \"\"\"\n",
    "    is_very_important = {}\n",
    "    is_important = {}\n",
    "    not_very_important = {}\n",
    "    not_important = {}\n",
    "    for name, weight in zip(weights.keys(), weights.values()):\n",
    "        if weight.round(0):\n",
    "            is_very_important[name] = weight\n",
    "        elif weight.round(1):\n",
    "            is_important[name] = weight\n",
    "        elif weight.round(2):\n",
    "            not_very_important[name] = weight\n",
    "        else:\n",
    "            not_important[name] = weight\n",
    "    return is_very_important, is_important, not_very_important, not_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_importances_report(model):\n",
    "    \"\"\"\n",
    "    Функція виводить повний звіт з важливості ознак в залежності від заданої точності.\n",
    "    \"\"\"\n",
    "    weights = model_weights(model)\n",
    "    is_very_important, is_important, not_very_important, not_important = (\n",
    "        weight_importances(weights)\n",
    "    )\n",
    "    print(\"Ваги всіх ознак:\")\n",
    "    for name, weight in zip(weights.keys(), weights.values()):\n",
    "        print(f\"{name}: {weight}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Найважливіші ознаки:\")\n",
    "    for w in is_very_important.keys():\n",
    "        print(w)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Значимі ознаки:\")\n",
    "    for w in is_important.keys():\n",
    "        print(w)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Несуттєві ознаки:\")\n",
    "    for w in not_very_important.keys():\n",
    "        print(w)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Неважливі ознаки:\")\n",
    "    for w in not_important.keys():\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Завантаження моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF_path = \"model_RandomForest.joblib\"\n",
    "model_HGB_path = \"model_HistGradientBoosting.joblib\"\n",
    "model_GB_path = \"model_GradientBoosting.joblib\"\n",
    "model_LR_path = \"model_LogisticRegression.joblib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF = load(model_RF_path)\n",
    "model_HGB = load(model_HGB_path)\n",
    "model_GB = load(model_GB_path)\n",
    "model_LR = load(model_LR_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF_name = \"Random Forest\"\n",
    "model_HGB_name = \"Histogram-based Gradient Boosting Classification Tree\"\n",
    "model_GB_name = \"Gradient Boosting\"\n",
    "model_LR_name = \"Logistic Regression\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Модель Random Forest__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Класифікаційний звіт для моделі Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     32224\n",
      "           1       1.00      0.98      0.99     40050\n",
      "\n",
      "    accuracy                           0.99     72274\n",
      "   macro avg       0.99      0.99      0.99     72274\n",
      "weighted avg       0.99      0.99      0.99     72274\n",
      "\n",
      "Розмір моделі: 35670553 B (34834.52 kB / 34.02 MB)\n"
     ]
    }
   ],
   "source": [
    "model_classification_report(model_RF, model_RF_name, X, y)\n",
    "model_RF_size = model_size(model_RF_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Модель Histogram-based Gradient Boosting Classification Tree__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Класифікаційний звіт для моделі Histogram-based Gradient Boosting Classification Tree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     32224\n",
      "           1       1.00      0.97      0.98     40050\n",
      "\n",
      "    accuracy                           0.98     72274\n",
      "   macro avg       0.98      0.98      0.98     72274\n",
      "weighted avg       0.98      0.98      0.98     72274\n",
      "\n",
      "Розмір моделі: 1976064 B (1929.75 kB / 1.88 MB)\n"
     ]
    }
   ],
   "source": [
    "model_classification_report(model_HGB, model_HGB_name, X, y)\n",
    "model_HGB_size = model_size(model_HGB_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Модель Gradient Boosting__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Класифікаційний звіт для моделі Gradient Boosting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97     32224\n",
      "           1       0.99      0.95      0.97     40050\n",
      "\n",
      "    accuracy                           0.97     72274\n",
      "   macro avg       0.97      0.97      0.97     72274\n",
      "weighted avg       0.97      0.97      0.97     72274\n",
      "\n",
      "Розмір моделі: 926285 B (904.58 kB / 0.88 MB)\n"
     ]
    }
   ],
   "source": [
    "model_classification_report(model_GB, model_GB_name, X, y)\n",
    "model_GB_size = model_size(model_GB_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Модель Logistic Regression__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Класифікаційний звіт для моделі Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87     32224\n",
      "           1       0.88      0.93      0.90     40050\n",
      "\n",
      "    accuracy                           0.89     72274\n",
      "   macro avg       0.89      0.89      0.89     72274\n",
      "weighted avg       0.89      0.89      0.89     72274\n",
      "\n",
      "Розмір моделі: 1439 B (1.41 kB / 0.00 MB)\n"
     ]
    }
   ],
   "source": [
    "model_classification_report(model_LR, model_LR_name, X, y)\n",
    "model_LR_size = model_size(model_LR_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Відсоткове співвідношення розмірів моделей__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 92.47%\n",
      "Histogram-based Gradient Boosting Classification Tree: 5.12%\n",
      "Gradient Boosting: 2.40%\n",
      "Logistic Regression: 0.00%\n"
     ]
    }
   ],
   "source": [
    "sum_sizes = model_RF_size + model_HGB_size + model_GB_size + model_LR_size\n",
    "print(f\"{model_RF_name}: {model_RF_size / sum_sizes * 100:.2f}%\")\n",
    "print(f\"{model_HGB_name}: {model_HGB_size / sum_sizes * 100:.2f}%\")\n",
    "print(f\"{model_GB_name}: {model_GB_size / sum_sizes * 100:.2f}%\")\n",
    "print(f\"{model_LR_name}: {model_LR_size / sum_sizes * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Визначення важливості ознак за допомогою моделей *Random Forest* і *Gradient Boosting*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель *Random Forest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ваги всіх ознак:\n",
      "remaining_contract: 0.7978162233940672\n",
      "download_avg: 0.0887780831201279\n",
      "subscription_age: 0.04147501909238496\n",
      "bill_avg: 0.03381152413351241\n",
      "upload_avg: 0.02509925171843683\n",
      "is_movie_package_subscriber: 0.007645825767476941\n",
      "service_failure_count: 0.003046797012352122\n",
      "is_tv_subscriber: 0.0018317512409608222\n",
      "download_over_limit: 0.0004955245206808143\n",
      "\n",
      "\n",
      "Найважливіші ознаки:\n",
      "remaining_contract\n",
      "\n",
      "\n",
      "Значимі ознаки:\n",
      "download_avg\n",
      "\n",
      "\n",
      "Несуттєві ознаки:\n",
      "subscription_age\n",
      "bill_avg\n",
      "upload_avg\n",
      "is_movie_package_subscriber\n",
      "\n",
      "\n",
      "Неважливі ознаки:\n",
      "service_failure_count\n",
      "is_tv_subscriber\n",
      "download_over_limit\n"
     ]
    }
   ],
   "source": [
    "weight_importances_report(model_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель *Gradient Boosting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ваги всіх ознак:\n",
      "remaining_contract: 0.921066359947278\n",
      "download_avg: 0.05571081374307791\n",
      "bill_avg: 0.009974121926515287\n",
      "subscription_age: 0.006614992250190256\n",
      "upload_avg: 0.004121893959959762\n",
      "is_movie_package_subscriber: 0.0013572162301059931\n",
      "is_tv_subscriber: 0.0005196293915680024\n",
      "service_failure_count: 0.00032580264163736665\n",
      "download_over_limit: 0.00030916990966741017\n",
      "\n",
      "\n",
      "Найважливіші ознаки:\n",
      "remaining_contract\n",
      "\n",
      "\n",
      "Значимі ознаки:\n",
      "download_avg\n",
      "\n",
      "\n",
      "Несуттєві ознаки:\n",
      "bill_avg\n",
      "subscription_age\n",
      "\n",
      "\n",
      "Неважливі ознаки:\n",
      "upload_avg\n",
      "is_movie_package_subscriber\n",
      "is_tv_subscriber\n",
      "service_failure_count\n",
      "download_over_limit\n"
     ]
    }
   ],
   "source": [
    "weight_importances_report(model_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Розмір моделі: 35670553 B (34834.52 kB / 34.02 MB)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../results/model_evaluation.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m model_RF_report \u001b[38;5;241m=\u001b[39m classification_report(y, model_RF\u001b[38;5;241m.\u001b[39mpredict(X), output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m model_RF_size_mb \u001b[38;5;241m=\u001b[39m model_size(model_RF_path) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m)  \u001b[38;5;66;03m# Конвертуємо в MB\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m save_results_to_json(model_RF_name, model_RF_report, model_RF_size_mb)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Повторюємо для інших моделей\u001b[39;00m\n\u001b[0;32m     32\u001b[0m model_HGB_report \u001b[38;5;241m=\u001b[39m classification_report(y, model_HGB\u001b[38;5;241m.\u001b[39mpredict(X), output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[48], line 23\u001b[0m, in \u001b[0;36msave_results_to_json\u001b[1;34m(model_name, classification_report, model_size)\u001b[0m\n\u001b[0;32m     17\u001b[0m results[model_name] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification_report\u001b[39m\u001b[38;5;124m\"\u001b[39m: classification_report,\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_size_mb\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_size,\n\u001b[0;32m     20\u001b[0m }\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Записуємо результати у JSON-файл\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(results_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     24\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(results, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results/model_evaluation.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# Шлях до файлу для збереження даних\n",
    "results_path = \"../results/model_evaluation.json\"\n",
    "\n",
    "# Функція для збереження даних у JSON-файл\n",
    "def save_results_to_json(model_name, classification_report, model_size):\n",
    "    # Перевіряємо, чи файл вже існує\n",
    "    if os.path.exists(results_path):\n",
    "        with open(results_path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        results = {}\n",
    "\n",
    "    # Додаємо дані для поточної моделі\n",
    "    results[model_name] = {\n",
    "        \"classification_report\": classification_report,\n",
    "        \"model_size_mb\": model_size,\n",
    "    }\n",
    "\n",
    "    # Записуємо результати у JSON-файл\n",
    "    with open(results_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "# Приклад для Random Forest\n",
    "model_RF_report = classification_report(y, model_RF.predict(X), output_dict=True)\n",
    "model_RF_size_mb = model_size(model_RF_path) / (1024 * 1024)  # Конвертуємо в MB\n",
    "save_results_to_json(model_RF_name, model_RF_report, model_RF_size_mb)\n",
    "\n",
    "# Повторюємо для інших моделей\n",
    "model_HGB_report = classification_report(y, model_HGB.predict(X), output_dict=True)\n",
    "model_HGB_size_mb = model_size(model_HGB_path) / (1024 * 1024)\n",
    "save_results_to_json(model_HGB_name, model_HGB_report, model_HGB_size_mb)\n",
    "\n",
    "model_GB_report = classification_report(y, model_GB.predict(X), output_dict=True)\n",
    "model_GB_size_mb = model_size(model_GB_path) / (1024 * 1024)\n",
    "save_results_to_json(model_GB_name, model_GB_report, model_GB_size_mb)\n",
    "\n",
    "model_LR_report = classification_report(y, model_LR.predict(X), output_dict=True)\n",
    "model_LR_size_mb = model_size(model_LR_path) / (1024 * 1024)\n",
    "save_results_to_json(model_LR_name, model_LR_report, model_LR_size_mb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Висновки щодо вибору моделі\n",
    "\n",
    "Розглянуто чотири моделі з бібліотеки `sklearn`. Здійснено оцінку *точності* моделей на усіх даних і на тестових даних за допомогою `classification_report` та *розміру* моделей.\n",
    "\n",
    "**Рейтинг моделей за точність на тестових даних (починаючи від найточнішої):**\n",
    "\n",
    "1. *Random Forest* та *Histogram-based Gradient Boosting Classification Tree*: 97%\n",
    "2. *Gradient Boosting*: 96%\n",
    "3. *Logistic Regression*: 89%\n",
    "\n",
    "**Коментарі:** Моделі *Random Forest* та *Histogram-based Gradient Boosting Classification Tree* показали однакові значення метрик якості. Метод *Gradient Boosting* має трохи нижчі значення метрик якості. Модель *Logistic Regression* має відчутно меншу точність ніж усі інші, але однаково залишається досить точною.\n",
    "\n",
    "**Рейтинг моделей за точність на усіх даних (починаючи від найточнішої):**\n",
    "\n",
    "1. *Random Forest*: 99%\n",
    "2. *Histogram-based Gradient Boosting Classification Tree*: 98%\n",
    "3. *Gradient Boosting*: 97%\n",
    "4. *Logistic Regression*: 89%\n",
    "\n",
    "**Коментарі:** На усіх даних найточнішою є модель *Random Forest*. Точність моделі *Histogram-based Gradient Boosting Classification Tree* менше ніж *Random Forest*, але різниця невелика. У моделі *Gradient Boosting* нижче точність ніж у *Histogram-based Gradient Boosting Classification Tree*, але різниця також невелика. Модель *Logistic Regression* має відчутно меншу точність ніж усі інші, але однаково залишається досить точною.\n",
    "\n",
    "**Рейтинг моделей за розміром (починаючи від найменшої):**\n",
    "\n",
    "1. *Logistic Regression*: 1.41 kB (0.00% від суми розмірів усіх моделей)\n",
    "2. *Gradient Boosting*: 0.88 MB (2.4% від суми розмірів усіх моделей)\n",
    "3. *Histogram-based Gradient Boosting Classification Tree*: 1.88 MB (5.12% від суми розмірів усіх моделей)\n",
    "4. *Random Forest*: 34.03 MB (92.47% від суми розмірів усіх моделей)\n",
    "\n",
    "**Коментарі:** Модель *Random Forest* важить набагато більше ніж інші моделі. Модель *Gradient Boosting* важить менше ніж *Histogram-based Gradient Boosting Classification Tree*, але різниця не є суттєвою. Модель *Logistic Regression* займає мінімальну кількість пам'яті.\n",
    "\n",
    "**Підсумуємо результати:**\n",
    "\n",
    "- Найточнішою є модель *Random Forest*, але й важить вона набагато більше ніж інші моделі.\n",
    "- Точність моделі *Histogram-based Gradient Boosting Classification Tree* трохи менше ніж у моделі *Random Forest*, але важить вона набагато менше. Також саме ця модель найкраще себе показала на тестових даних.\n",
    "- Модель *Gradient Boosting* має трохи нижчу точність та розмір ніж модель *Histogram-based Gradient Boosting Classification Tree*, але різниця не є суттєвою.\n",
    "- Модель *Logistic Regression* має відчутно меншу точність ніж усі інші, але однаково залишається досить точною. До того ж модель займає мінімальну кількість пам'яті. Для *задачі прогнозування відтоку клієнтів* висока точність не є критично необхідною, тому модель має право на існування.\n",
    "\n",
    "**Рекомендації:**\n",
    "\n",
    "- Якщо обирати \"золоту середину\" між точністю та розміром, то варто обрати *Histogram-based Gradient Boosting Classification Tree*. Модель має високу точність і невеликий розмір.\n",
    "- Якщо критично важлива точність, то варто обрати *Random Forest*.\n",
    "- Якщо критично важливим є розмір, то варто обрати *Logistic Regression*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Висновки щодо важливості ознак\n",
    "\n",
    "**Рейтинг ознак:**\n",
    "\n",
    "- *Найважливіша:*\n",
    "1. `reamining_contract`\n",
    "\n",
    "- *Значима:*\n",
    "\n",
    "2. `download_avg`\n",
    "\n",
    "- *Несуттєві:*\n",
    "\n",
    "3. `subscription_age`\n",
    "\n",
    "4. `bill_avg`\n",
    "\n",
    "- *Майже несуттєві:*\n",
    "\n",
    "5. `upload_avg`\n",
    "\n",
    "6. `is_movie_package_subscriber`\n",
    "\n",
    "- *Неважливі:*\n",
    "\n",
    "7. `service_failure_count`\n",
    "\n",
    "8. `is_tv_subscriber`\n",
    "\n",
    "9. `download_over_limit`\n",
    "\n",
    "Отже, відток клієнтів **сильно залежить** від *терміну залишку контракту* і **незалежить** від *кількісті збоїв сервісу*, *наявності підписки на ТБ* та *перевищення ліміту завантаження*. Також відток клієнтів **помірно залежить** від *середньої швидкості завантаження*, **слабо залежить** від *тривалості підписки* і *розміру середнього рахунку* та **майже незалежить** від *середньої швидкості вивантаження* і *наявності пакету фільмів*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
